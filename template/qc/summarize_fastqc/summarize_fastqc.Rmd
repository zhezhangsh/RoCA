---
title: "Summary of FastQC reports"
author: "`r if (exists('yml')) yml$analyst else 'Jim Zhang'`"
date: "`r Sys.Date()`"
output:
  html_document:
    number_sections: yes
    self_contained: no
    toc: yes
    toc_float:
      collapsed: no
---

<div style="border:black 1px solid; padding: 0.5cm 0.5cm">
**Introduction** This analysis compares a set of high-throughput sequencing libraries based on their [FastQC](http://www.bioinformatics.babraham.ac.uk/projects/fastqc/) reports. Please refer to the original FastQC documentation for details about FastQC statistics. This analysis only requires the _fastqc.zip_ file generated by each FastQC run and don't use the original .fastq or .bam file.

[FastQC](http://www.bioinformatics.babraham.ac.uk/projects/fastqc/) aims to provide a simple way to do some quality control checks on raw sequence data coming from high throughput sequencing pipelines. It provides a modular set of analyses which you can use to give a quick impression of whether your data has any problems of which you should be aware before doing any further analysis. The main functions of FastQC are

 - Import of data from BAM, SAM or FastQ files (any variant)
 - Providing a quick overview to tell you in which areas there may be problems
 - Summary graphs and tables to quickly assess your data
 - Export of results to an HTML based permanent report
 - Offline operation to allow automated generation of reports without running the interactive application

</div>

&nbsp;

```{r global_setup, eval=TRUE, include=FALSE}
name.yaml <- 'summarize_fastqc.yaml'; 
name.packages <- c('rmarkdown', 'knitr', 'kableExtra', 'yaml', 'DT', 'htmlwidgets', 'gplots', 
                   'GtUtility', 'RoCA', 'awsomics'); 
name.subfolders <- c('path.input'='input', 'path.r'='R', 'path.fig'='figure', 'path.tbl'='table'); # <full.path.to.subfolder>=<subfolder.name>

## Default knitr parameters
knitr::opts_chunk$set(dpi=300, dev=c('png', 'pdf'), echo=FALSE, warning=FALSE, message=FALSE);
if (!require(devtools)) { install.packages('devtools'); require(devtools); }
if (!require(RCurl)) { install.packages('RCurl'); require(RCurl); }
if (!require(RoCA)) { install_github('zhezhangsh/RoCAR'); require(RoCA); }

## Load required R packages
loaded <- LoadPackage(name.packages);
if (length(loaded[!loaded])) stop('Error: failed to load package(s) ', paste(names(loaded[!loaded]), collapse=', '));

## By default, before knitting this R Markdown file, the YAML file pairing it has been loaded.
## But, the developer can also provide the option to load the YAML file on the fly.
## So, the template can be run using the "Knit HTML" button in RStudio
if (!exists('yml'))                   # if the 'yml' variable doesn't exist yet, create it by loading the YAML file
  if (file.exists(name.yaml))         # assume the pairing YAML file exists in the current folder with the same name
    yml<-yaml.load_file(name.yaml);   # rename the YAML file to fit this template

prms <- yml$parameter;

## Generate directory and sub-directories where the output files will be
f <- GenerateFolder(yml$output, name.subfolders);
path <- yml$output;
for (i in 1:length(name.subfolders)) assign(names(name.subfolders)[i], f[name.subfolders[i]]); 

## Automatical figure/table ordering
OrderFigure(reset=TRUE);
OrderTable(reset=TRUE);

## URL to project home
## Use this line to add a link to project home in the report: `r home.url`
home.url <- Link2Home(yml$home);
```

```{r load_data, include=FALSE}
## Load input data
fns.zip<-lapply(yml$input$fastqc, function(f) sapply(f, function(f) DownloadFile(f, path.input))); 
# fns.zip<-lapply(yml$input$fastqc, function(f) sapply(f, function(f) {
#   fn<-paste(path.input, TrimPath(f), sep='/'); 
#   if (!file.exists(fn)) DownloadFile(f, path.input) else fn;
# }));
N<-length(fns.zip);

if (min(sapply(fns.zip, length))>=2) paired<-TRUE else paired<-FALSE;

stat.all<-lapply(fns.zip, function(fns) {
  stat<-lapply(fns, function(f) parseFastQC(f, path.input)); 
  names(stat)<-paste('R', 1:length(stat), sep=''); 
  stat;
});
if (paired) stat.all<-lapply(stat.all, function(x) x[1:2]) else stat.all<-lapply(stat.all, function(x) x[1]); 
saveRDS(stat.all, paste(path.r, 'stat_all_libraries.rds', sep='/'));

snm<-names(stat.all);
if (paired) snm<-paste(rep(snm, each=2), rep(c('R1', 'R2'), length(snm)), sep='_'); 
```

`r home.url`

# Description

`r WriteDescription(yml$description)`

`r home.url`

# Summary statistics

```{r retrieve_stats, include=FALSE}
# Per sequence quality scores
qual<-t(sapply(stat.all, function(s) sapply(s, function(s) {
  sc<-s[["Per sequence quality scores"]];
  sum(sc[,1]*sc[,2]/10^6)/sum(sc[,2]/10^6);
})));

# Per sequence GC content
gc<-t(sapply(stat.all, function(s) sapply(s, function(s) {
  sc<-s[["Per sequence GC content"]];
  sum(sc[,1]*sc[,2]/10^6)/sum(sc[,2]/10^6);
})));

# Per base N content
ns<-t(sapply(stat.all, function(s) sapply(s, function(s) {
  pct<-s[["Per base N content"]];
  mean(pct, weighted.mean(c(rep(2, 9), rep(1, length(pct)-9))));
})));

# Sequence Duplication Levels
dup<-t(sapply(stat.all, function(s) sapply(s, function(s) {
  pct<-s[["Sequence Duplication Levels"]];
  sum(pct[2:nrow(pct), 2]);
})));

d<-list(qual, gc, ns, dup);
names(d)<-c("Average score of sequence quality", "Overall percentage of GC bases", "Average percentage of Ns", "Percentage of duplicated reads")
```

```{r summary_statistics, include=FALSE}
# Total reads
ttl<-sapply(stat.all, function(s) s[[1]][[2]][['Total Sequences']]);

# Average quality
qual<-sapply(stat.all, function(s) sapply(s, function(s) {
  sc<-s[["Per sequence quality scores"]];
  sum(sc[,1]*sc[,2]/10^6)/sum(sc[,2]/10^6);
}));

# GC percent
gc<-sapply(stat.all, function(s) sapply(s, function(s) {
  sc<-s[["Per sequence GC content"]];
  sum(sc[,1]*sc[,2]/10^6)/sum(sc[,2]/10^6);
}));

# N percent
ns<-sapply(stat.all, function(s) sapply(s, function(s) {
  pct<-s[["Per base N content"]];
  mean(pct, weighted.mean(c(rep(2, 9), rep(1, length(pct)-9))));
}));

# Duplicated percent
dup<-sapply(stat.all, function(s) sapply(s, function(s) {
  pct<-s[["Sequence Duplication Levels"]];
  sum(pct[2:nrow(pct), 2]);
}));

if (!paired) stats<-cbind(ttl/10^6, qual, gc, ns, dup) else stats<-t(rbind(ttl/10^6, qual, gc, ns, dup));
stats<-FormatNumeric(stats);
cnm<-c("Average_quality_score", 'GC_percent', 'N_percent', 'Duplicated_reads_percent');
if (!paired) colnames(stats)<-c('Total_reads_in_million', cnm) else 
  colnames(stats)<-c('Total_reads_in_million', paste(rep(cnm, each=2), colnames(stats)[-1], sep='_'));
fn.tbl<-CreateDatatable(stats, paste(path.tbl, 'summary_stats.html', sep='/'), rownames = TRUE, caption = 'Summary statistics');
```

Summary statistics were compared across libraries. Inconsistence of a statistics might indicate quality issues of some libraries. 

`r home.url`

## Quick evaluation

```{r quick_eval, include=FALSE}
mp<-c('PASS'=1, 'WARN'=2, 'FAIL'=3);
nm<-unique(unlist(lapply(stat.all, function(s) sapply(s, function(s) names(s$Summary))), use.names=FALSE));

code<-lapply(stat.all, function(s) {
  s<-sapply(s, function(s) mp[s$Summary[nm]]); 
});
code<-do.call('cbind', code); 
rownames(code)<-nm;
colnames(code)<-snm;

code[code==0 | is.na(code)]<-4
tbl<-apply(code, 1, function(x) names(mp)[x]);
rownames(tbl)<-snm;
fn.tbl<-CreateDatatable(tbl, paste(path.tbl, 'quick_evaluation.html', sep='/'), rownames = TRUE, caption = "Quick evaluation");
saveRDS(tbl, paste(path.r, 'quick_evaluation.rds', sep='/'));
write.csv(tbl, paste(path.tbl, 'quick_evaluation.csv', sep='/')); 
```

**FastQC** makes a quick evaluation on each summary statistic whether it is entirely normal (**green**), slightly abnormal (**orange**) or abnormal (**red**). The figure below compiles the evaluation results of all summary statistics from all libraries. 

  - **[Quick evaluation results of all libraries](table/quick_evaluation.html)**

<div align='center'>
```{r quick_eval_heatmap, include=TRUE, fig.width=2+0.5*nrow(code), fig.height=2+min(6, 0.25*ncol(code)), out.width='720px'}
col<-c('#00FF00DD', '#FFA400DD', '#FF0000DD', '#11111111');
code<-code[, ncol(code):1, drop=FALSE];

par(mai=c(0.25, 2, 2, 0.25));
plot(0, type='n', xlim=c(0, nrow(code)), ylim=c(0, ncol(code)), axes=FALSE, xaxs='i', yaxs='i', xlab='', ylab='');
rect(rep(1:nrow(code), each=ncol(code))-1, rep(1:ncol(code), nrow(code))-1, 
     rep(1:nrow(code), each=ncol(code)), rep(1:ncol(code), nrow(code)), 
     col=col[as.vector(t(code))], border=NA);

axis(2, at=1:ncol(code)-0.5, tick=FALSE, las=2, labels=colnames(code),
     cex.axis=min(1.5/max(strwidth(colnames(code), units='inch')), 
                  0.125/max(strheight(colnames(code), units='inch'))));
axis(3, at=1:nrow(code)-0.5, tick=FALSE, las=2, cex=1.5,
     labels=sapply(rownames(code), function(rnm) paste(strwrap(rnm, 20), collapse='\n')))
axis(3, at=0:nrow(code), label=rep('', 1+nrow(code)));
abline(v=0:nrow(code), col='darkgrey');
if (paired) {
  abline(h=seq(0, ncol(code), 2), col='darkgrey');
  abline(h=seq(1, ncol(code), 2), col='white');
}else abline(h=0:ncol(code), col='darkgrey'); 
box();
```
</div>

<div style="color:darkblue; padding:0 2.5cm">
**Figure 1.** The summary statistics are color-coded (green=normal, orange=slightly abnormal, and red=abnormal). Please refer to FastQC manual for intepretation of each statistic.
</div>

`r home.url`

## Total reads

<div align='center'>
```{r total_reads, include=TRUE, fig.width=8, fig.height=6, out.width='600px'}
par(mar=c(5,5,3,2));
hist(ttl/10^6, xlab='Number of reads (in million)', ylab='Number of libraries', cex.lab=2, main='Total reads per library', cex.main=2, col='lightgrey');
```
</div>

<div style="color:darkblue; padding:0 3cm">
**Figure 2.** The distribution of library size (number of total reads). One pair of paired reads is counted as one read.
</div>

`r home.url`

## Paired read correlation

Compare the consistency of several key summary statistics between paired sequence reads. Strong agreement between pairs is expected.
`r if (!paired) "***No results in this section because the sequencing reads are single-ended***"`

  - **[Summary statistics to be compared between paired reads](table/summary_stats.html)**

<div align='center'>
```{r between_pair, include=TRUE, fig.width=8, fig.height=if (paired) 8 else 1, out.width='640px'}
if (paired) {
  par(mfrow=c(2, 2), mar=c(5, 5, 3, 3));
  fn<-sapply(names(d), function(nm) {
    plot(d[[nm]], main=nm, cex.main=1.5, pch=19, col='#88888888', cex=max(0.5, min(3, 150/N)), xlab='R1', ylab='R2', cex.lab=2, xlim=c(min(d[[nm]]), max(d[[nm]])), ylim=c(min(d[[nm]]), max(d[[nm]])));
    abline(0, 1, col='green', lwd=2, lty=2);
    corr<-round(cor(d[[nm]][, 1], d[[nm]][, 2], use='pair'), 4);
    text(min(d[[nm]]), max(d[[nm]]), label=paste('R', corr, sep=' = '), cex=1, pos=4, col='blue')
  }); 
} else {
  par(mar=c(0,0,0,0));
  plot(0, axes=FALSE, xlab='', ylab='', type='n');
  text(1, 0, pos=3, label='Empty plot', col='darkgreen', cex=2);
  box();
}
```
</div>

<div style="color:darkblue; padding:0 2cm">
**Figure 3.** These plots compare the summary statistics of paired reads (R1 = read1 and R2 = read2). Each dot represents a library. No plots will be shown if the sequencing reads are single-ended. 
</div>

`r home.url`

## Per read statistics

### Sequencing quality

<div align='center'>
```{r average_quality, include=TRUE, fig.width=8, fig.height=6, out.width='600px'}
par(mai=c(2,1,0.2,0.2));
rng<-c(0, 1.1*max(qual)); 
cex<-1.5/max(strwidth(names(stat.all), unit='inch'));
if (paired) {
  q<-qual[, rev(order(colSums(qual))), drop=FALSE];
  barplot(q, beside = TRUE, las=3, cex.names=cex, ylim=rng, ylab='Average quality score', cex.lab=1.5, legend=c('R1', 'R2'));
} else {
  q<-qual[rev(order(qual))];
  barplot(q, col='lightgrey', las=3, cex.names=cex, ylim=rng, ylab='Average quality score', cex.lab=1.5);
}
abline(h=0, lwd=2);
```
</div>

<div style="color:darkblue; padding:0 3cm">
**Figure 4.** Each base in a sequencing read got a quality score. This plot shows the average quality score of all bases and all reads in each library. The scores from Illumina sequencers usually range from 0 (p=1) to 40 (p=1E-4). 
</div>

### GC percent

<div align='center'>
```{r gc_percent, include=TRUE, fig.width=8, fig.height=6, out.width='600px'}
par(mai=c(2,1,0.2,0.2));
rng<-c(0, 1.1*max(gc)); 
cex<-1.5/max(strwidth(names(stat.all), unit='inch'));
if (paired) {
  x<-gc[, rev(order(colSums(gc))), drop=FALSE];
  barplot(x, beside = TRUE, las=3, cex.names=cex, ylim=rng, ylab='Average GC percent', cex.lab=1.5, legend=c('R1', 'R2'));
} else {
  x<-gc[rev(order(gc))];
  barplot(x, col='lightgrey', las=3, cex.names=cex, ylim=rng, ylab='Average GC percent', cex.lab=1.5);
}
abline(h=0, lwd=2);
```
</div>

<div style="color:darkblue; padding:0 3cm">
**Figure 5.** The average GC percent of all reads in each library.
</div>

### N percent

<div align='center'>
```{r n_percent, include=TRUE, fig.width=8, fig.height=6, out.width='600px'}
par(mai=c(2,1,0.2,0.2));
rng<-c(0, 1.1*max(ns)); 
cex<-1.5/max(strwidth(names(stat.all), unit='inch'));
if (paired) {
  x<-ns[, rev(order(colSums(ns))), drop=FALSE];
  barplot(x, beside = TRUE, las=3, cex.names=cex, ylim=rng, ylab='Average N percent', cex.lab=1.5, legend=c('R1', 'R2'));
} else {
  x<-ns[rev(order(ns))];
  barplot(x, col='lightgrey', las=3, cex.names=cex, ylim=rng, ylab='Average N percent', cex.lab=1.5);
}
abline(h=0, lwd=2);
```
</div>

<div style="color:darkblue; padding:0 3cm">
**Figure 6.** The average N frequency of all reads in each library. 
</div>

### Duplication level

Duplicated reads have the exact same sequences. Duplicated reads are often treated as one read in variant calling, so higher percentage of duplicated reads reduces the total number of usable reads. However, the duplication of paired end reads is evaluated separately by FastQC, so the actual level of duplication might be lower than the number in FastQC report. 

<div align='center'>
```{r dup_percent, include=TRUE, fig.width=8, fig.height=6, out.width='600px'}
par(mai=c(2,1,0.2,0.2));
rng<-c(0, 1.1*max(dup)); 
cex<-1.5/max(strwidth(names(stat.all), unit='inch'));
if (paired) {
  x<-dup[, rev(order(colSums(dup))), drop=FALSE];
  barplot(x, beside = TRUE, las=3, cex.names=cex, ylim=rng, ylab='Average duplication percent', cex.lab=1.5, legend=c('R1', 'R2'));
} else {
  x<-dup[rev(order(dup))];
  barplot(x, col='lightgrey', las=3, cex.names=cex, ylim=rng, ylab='Average duplication percent', cex.lab=1.5);
}
abline(h=0, lwd=2);
```
</div>

<div style="color:darkblue; padding:0 3cm">
**Figure 7.** The average frequency of duplicated reads in each library. 
</div>

`r home.url`

## Per base statistics

### Sequence quality

```{r perbase_quality, include=FALSE}
sc<-lapply(stat.all, function(s) sapply(s, function(s) s[["Per base sequence quality"]][, 1]));
sc<-do.call('cbind', sc); 
colnames(sc)<-snm;

fn.tbl<-CreateDatatable(FormatNumeric(t(sc)), paste(path.tbl, 'perbase_quality.html', sep='/'), rownames = TRUE, caption = "Per base sequence quality");
```

Sequence quality of single bases is often position-dependent, with later positions usually having lower quality scores. 

  - **[Position-specific quality scores of all libraries](table/perbase_quality.html)** 

<div align='center'>
```{r perbase_quality_heatmap, include=TRUE, fig.width=2+max(6, 0.1*nrow(sc)), fig.height=1+min(4, 0.25*ncol(sc)), out.width='720px'}
PlotColoredBlock(t(sc), group=as.list(rownames(sc)), key='Quality score');
```
</div>

<div style="color:darkblue; padding:0 2.5cm">
**Figure 8.** The average of position-specific quality scores in each library (red = higher).
</div>

### GC content

```{r perbase_content, include=FALSE}
pct<-lapply(stat.all, function(s) sapply(s, function(s) rowSums(s[["Per base sequence content"]][, c('G', 'C')])));
pct<-do.call('cbind', pct); 
colnames(pct)<-snm;

fn.tbl<-CreateDatatable(FormatNumeric(t(pct)), paste(path.tbl, 'perbase_content.html', sep='/'), rownames = TRUE, caption = "Per base GC content");
```

Sequence GC content of single bases is often position-dependent too.

  - **[Position-specific GC content of all libraries](table/perbase_content.html)** 

<div align='center'>
```{r perbase_content_heatmap, include=TRUE, fig.width=2+max(6, 0.1*nrow(pct)), fig.height=1+min(4, 0.25*ncol(pct)), out.width='720px'}
PlotColoredBlock(t(pct), group=as.list(rownames(pct)), key='GC percent');
```
</div>

<div style="color:darkblue; padding:0 2.5cm">
**Figure 9.** The average of position-specific GC content in each library (red = higher).
</div>

### N content

```{r perbase_N_content, include=FALSE}
npct<-lapply(stat.all, function(s) sapply(s, function(s) s[["Per base N content"]]));
npct<-do.call('cbind', npct); 
colnames(npct)<-snm;

fn.tbl<-CreateDatatable(FormatNumeric(t(npct)), paste(path.tbl, 'perbase_N_content.html', sep='/'), rownames = TRUE, caption = "Per base N content");
```

The occurance of Ns is also position-specific. 

  - **[Position-specific occurance of Ns in all libraries](table/perbase_N_content.html)** 

<div align='center'>
```{r perbase_N_content_heatmap, include=TRUE, fig.width=2+max(6, 0.1*nrow(pct)), fig.height=1+min(4, 0.25*ncol(pct)), out.width='720px'}
PlotColoredBlock(t(npct), group=as.list(rownames(npct)), key='N percent');
```
</div>

<div style="color:darkblue; padding:0 2.5cm">
**Figure 10.** The average of position-specific GC content in each library (red = higher).
</div>

### Adaptor content

```{r adaptor_content, include=FALSE}
dpt<-lapply(stat.all, function(s) lapply(s, function(s) s[["Adapter Content"]]));
dpt.mn<-rowMeans(do.call('cbind', lapply(dpt, function(x) sapply(x, colMeans))), na.rm=TRUE);
dpt.ind<-which(dpt.mn==max(dpt.mn));
dpt.nm<-names(dpt.mn)[dpt.ind];

dpt<-do.call('cbind', lapply(dpt, function(s) sapply(s, function(s) s[, dpt.ind]))); 
colnames(dpt)<-snm;

fn.tbl<-CreateDatatable(FormatNumeric(t(dpt)), paste(path.tbl, 'adaptor_content.html', sep='/'), rownames = TRUE, caption = "Per base sequence content");
```

Among commonly known adaptor sequences, ***`r dpt.nm`***, had the highest occurances in the sequencing reads. So, only the occurance of this adaptor was summarized.

  - **[Occurance of adaptor sequence at different positions in reads](table/adaptor_content.html)** 

<div align='center'>
```{r adaptor_content_heatmap, include=TRUE, fig.width=2+max(6, 0.1*nrow(dpt)), fig.height=1+min(4, 0.25*ncol(dpt)), out.width='720px'}
PlotColoredBlock(t(dpt), group=as.list(rownames(dpt)), key='Duplication level');
```
</div>

<div style="color:darkblue; padding:0 2.5cm">
**Figure 11.** The position-specific percent of the occurance of adaptor sequence, ***`r dpt.nm`*** (red = higher).
</div>

`r home.url`

## K-mer enrichment

```{r kmer, include=FALSE}
k<-lapply(do.call('c', stat.all), function(s) s[['Kmer Content']]); 
names(k)<-snm;
mer<-rev(sort(table(unlist(lapply(k, rownames), use.names=FALSE))));
kmer.stat<-sapply(names(mer), function(m) {
  s<-t(sapply(k, function(k) as.numeric(k[m, ])));
  s<-s[!is.na(s[, 1]), , drop=FALSE];
  c(mean(s[, 1]), mean(s[, 3]), mean(s[, 4]), min(s[, 4]), max(s[, 4]));
});
tbl0<-cbind(as.vector(mer), t(kmer.stat));
if (ncol(tbl0) == 6) {
  colnames(tbl0)<-c('Library', 'Count', 'Obs/Exp', 'Position_Mean', 'Position_Min', 'Position_Max'); 
  tbl0<-tbl0[order(rownames(tbl0)), ];
  tbl0<-tbl0[order(tbl0[, 1], decreasing = TRUE), ];
  saveRDS(k, paste(path.r, 'kmer_library.rds', sep='/'));
  saveRDS(tbl0, paste(path.r, 'kmer_summary.rds', sep='/')); 

  tbl<-tbl0[tbl0[, 1]>=tbl0[min(nrow(tbl0), yml$parameter$kmer), 1], , drop=FALSE];

  mtr<-matrix(NA, nr=nrow(tbl0), nc=length(k)+1, dimnames = list(rownames(tbl0), c('Num_library', snm)));
  mtr[, 1]<-tbl0[, 1];
  mtrs<-lapply(c(1, 3, 4), function(c) {
    for (i in 1:length(k)) mtr[rownames(k[[i]]), snm[i]]<-k[[i]][, c];
    mtr;
  });
  names(mtrs)<-c('count', 'enrichment', 'position'); 
  fn<-sapply(names(mtrs), function(nm) {
    CreateDatatable(mtrs[[nm]], paste(path.tbl, '/kmer_', nm, sep='')); 
  });
} else {
  tbl <- tbl0;
}
```

**FastQC** identifies top Kmers that were enriched in each library with their total occurance (count), significance (p value), enrichment (observed/expected), and the base position with maximum enrichment. Kmers of all libraries were summarized below. Use **Table 2** for details about Kmers in individual libraries.

  - [Kmer count](table/kmer_count.html)
  - [Kmer max enrichment](table/kmer_enrichment.html)
  - [Kmer max positioin](table/kmer_position.html)

`r OrderTable()` Top `r nrow(tbl)` Kmers that were enriched in multiple libraries.

`r kable(tbl) %>% kable_styling(
    bootstrap_options = c("striped", "hover", "condensed", "responsive"), position='left', font=12, full_width=FALSE)`

`r home.url`

# FastQC reports

```{r write_tables, include=FALSE}
fn<-TrimPath(sub('.zip$', '', unlist(fns.zip, use.names=FALSE), ignore.case = TRUE));
stats<-do.call('c', stat.all);
names(stats)<-fn;
fns<-sapply(names(stats), function(nm) {
  pth<-paste(path.input, nm, 'Tables', sep='/');
  if (!dir.exists(pth)) dir.create(pth, recursive = TRUE);
  s<-stats[[nm]];
  cll<-sapply(s, class);
  s<-s[cll=='matrix' | cll=='data.frame'];
  names(s)<-tolower(gsub(' ', '_', names(s)));
  sapply(names(s), function(f) CreateDatatable(s[[f]], paste(pth, f, sep='/'))); 
}); 

```

## Per read

```{r table_per_read, include=FALSE}
fn.img<-c('Quality'='per_sequence_quality.png', 'GC_percent' = 'per_sequence_gc_content.png',
      'Length' = 'sequence_length_distribution.png', 'Duplication' = 'duplication_levels.png',
      'Overrepresented' = NA, 'Kmer' = NA);
fn.tbl<-c('Quality'='per_sequence_quality_scores.html', 'GC_percent' = 'per_sequence_gc_content.html',
      'Length' = 'sequence_length_distribution.html', 'Duplication' = 'sequence_duplication_levels.html',
      'Overrepresented' = 'overrepresented_sequences.html', 'Kmer' = 'kmer_content.html');
tbl<-sapply(fn.img, function(img) paste('[image](input/', fn, '/Images/', img, ')', sep=''));
tbl<-cbind(Library=paste('[', snm, '](input/', fn, '/fastqc_report.html', ')', sep=''), tbl);
tbl<-sapply(fn, function(f) {
  f.img<- paste('input/', f, '/Images/', fn.img, sep=''); 
  f.tbl<- paste('input/', f, '/Tables/', fn.tbl, sep=''); 
  lnk.img<-paste('[image](', f.img, ')', sep='');
  lnk.tbl<-paste('[table](', f.tbl, ')', sep='');
  lnk.img[!file.exists(paste(path, f.img, sep='/'))]<-'image';
  lnk.tbl[!file.exists(paste(path, f.tbl, sep='/'))]<-'table';
  paste(lnk.img, lnk.tbl, sep=';');
});
rownames(tbl)<-names(fn.img);
tbl<-cbind(Library=paste('[', snm, '](input/', fn, '/fastqc_report.html', ')', sep=''), t(tbl));
```

`r OrderTable()` Click links to view full reports and individual plots of per read statistics.

`r kable(tbl, row.names=FALSE) %>% kable_styling(
    bootstrap_options = c("striped", "hover", "condensed", "responsive"), position='left', font=12, full_width=FALSE)`

`r home.url`

## Per base

```{r table_per_base, include=FALSE}
fn.img<-c('Base_quality' = 'per_base_quality.png', 'Tile_quality' = 'per_tile_quality.png',
          'GC_content' = 'per_base_sequence_content.png', 'N_content' = 'per_base_n_content.png', 
          'Kmer_profile' = 'kmer_profiles.png', 'Adapter_content' = 'adapter_content.png');
fn.tbl<-c('Base_quality' = 'per_base_sequence_quality.html', 'Tile_quality' = 'per_tile_sequence_quality.html',
          'GC_content' = 'per_base_sequence_content.html', 'N_content' = NA, 
          'Kmer_profile' = 'kmer_content.html', 'Adapter_content' = 'adapter_content.html');
tbl<-sapply(fn, function(f) {
  f.img<- paste('input/', f, '/Images/', fn.img, sep=''); 
  f.tbl<- paste('input/', f, '/Tables/', fn.tbl, sep=''); 
  lnk.img<-paste('[image](', f.img, ')', sep='');
  lnk.tbl<-paste('[table](', f.tbl, ')', sep='');
  lnk.img[!file.exists(paste(path, f.img, sep='/'))]<-'image';
  lnk.tbl[!file.exists(paste(path, f.tbl, sep='/'))]<-'table';
  paste(lnk.img, lnk.tbl, sep=';');
});
rownames(tbl)<-names(fn.img);
tbl<-cbind(Library=paste('[', snm, '](input/', fn, '/fastqc_report.html', ')', sep=''), t(tbl));
```

`r OrderTable()` Click links to view full reports and individual plots of per base statistics.

`r kable(tbl, row.names=FALSE) %>% kable_styling(
    bootstrap_options = c("striped", "hover", "condensed", "responsive"), position='left', font=12, full_width=FALSE)`

`r home.url`

***

# Appendix 

Check out the **[RoCA home page](http://zhezhangsh.github.io/RoCA)** for more information.  

## Reproduce this report

To reproduce this report: 

  1. Find the data analysis template you want to use and an example of its pairing YAML file  [here](https://github.com/zhezhangsh/RoCA/wiki/Templates-and-examples) and download the YAML example to your working directory

  2. To generate a new report using your own input data and parameter, edit the following items in the YAML file:

    - _output_        : where you want to put the output files
    - _home_          : the URL if you have a home page for your project
    - _analyst_       : your name
    - _description_   : background information about your project, analysis, etc.
    - _input_         : where are your input data, read instruction for preparing them
    - _parameter_     : parameters for this analysis; read instruction about how to prepare input data

  3. Run the code below within ***R Console*** or ***RStudio***, preferablly with a new R session:

```{r reproduce_report, eval=FALSE, echo=TRUE}
if (!require(devtools)) { install.packages('devtools'); require(devtools); }
if (!require(RCurl)) { install.packages('RCurl'); require(RCurl); }
if (!require(RoCA)) { install_github('zhezhangsh/RoCAR'); require(RoCA); }

CreateReport(filename.yaml);  # filename.yaml is the YAML file you just downloaded and edited for your analysis
```

If there is no complaint, go to the _output_ folder and open the ***index.html*** file to view report. 

## Session information

```{r session_info, echo=FALSE}
sessionInfo(); 
```

`r home.url`

***
_END OF DOCUMENT_
