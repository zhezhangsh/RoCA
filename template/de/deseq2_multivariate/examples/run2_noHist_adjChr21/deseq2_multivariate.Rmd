---
title: "Differential gene expression using DESeq2"
author: "`r if (exists('yml')) yml$analyst else 'Jim Zhang'`"
date: "`r Sys.Date()`"
output:
  html_document:
    number_sections: yes
    self_contained: no
    toc: yes
    toc_float:
      collapsed: no
---

<div style="border:black 1px solid; padding: 0.5cm 0.5cm">
This procedure uses the [DESeq2](https://bioconductor.org/packages/release/bioc/html/DESeq2.html) package to analyze RNA-seq read count data, or similar integer matrix, with a multi-factor design. Therefore, it allows for testing differential expression between two conditions while there are confounding variables. It takes an integer matrix of gene-level read counts, normalizes it across samples, compare their gene expression profiles, and run DESeq2 to test differential expression. 
</div>

&nbsp;

```{r global_setup, include=FALSE}
name.yaml <- 'deseq2_multivariate.yaml'; 
name.packages <- c('rmarkdown', 'knitr', 'kableExtra', 'yaml', 'DT', 'htmlwidgets', 'MASS', 'gplots', 'sva',
                   'colorspace', 'RoCA', 'rchive', 'awsomics', 'DESeq2', 'DEGandMore'); 
name.subfolders <- c('path.input'='input', 'path.r'='R', 'path.fig'='figure', 'path.tbl'='table', 'path.deg'='deg');

## Default knitr parameters
knitr::opts_chunk$set(dpi=300, dev=c('png', 'pdf'), echo=FALSE, warning=FALSE, message=FALSE, fig.path='figure/');

if (!require(devtools)) { install.packages('devtools'); require(devtools); }
if (!require(RCurl)) { install.packages('RCurl'); require(RCurl); }
if (!require(RoCA)) { install_github('zhezhangsh/RoCAR'); require(RoCA); }

## Load required R packages
loaded <- LoadPackage(name.packages);
if (length(loaded[!loaded])) stop('Error: failed to load package(s) ', paste(names(loaded[!loaded]), collapse=', '));

if (!exists('yml'))                   # if the 'yml' variable doesn't exist yet, create it by loading the YAML file
  if (file.exists(name.yaml))         # assume the pairing YAML file exists in the current folder with the same name
    yml <- yaml.load_file(name.yaml);   # rename the YAML file to fit this template

prms <- yml$parameter;

f <- GenerateFolder(yml$output, name.subfolders);
path <- yml$output;
for (i in 1:length(name.subfolders)) assign(names(name.subfolders)[i], f[name.subfolders[i]]); 

OrderFigure(reset=TRUE);
OrderTable(reset=TRUE);

home.url <- Link2Home(yml$home);
```

```{r include=FALSE}
inputs <- yml$input;

# All input variables
anno    <- inputs$anno      <- ImportTable(DownloadFile(inputs$anno, path.input));
cnt0    <- inputs$count     <- as.matrix(ImportTable(DownloadFile(inputs$count, path.input)));
smpl    <- inputs$sample    <- ImportR(DownloadFile(inputs$sample, path.input));

smpl <- smpl[rownames(smpl) %in% colnames(cnt0), , drop=FALSE];
cnt0 <- cnt0[, rownames(smpl), drop=FALSE];

for (i in 1:ncol(smpl)) smpl[[i]] <- as.factor(smpl[[i]]);
g0 <- prms$comparison$group0;
g1 <- prms$comparison$group1;
s0 <- rownames(smpl)[as.vector(smpl[[prms$comparison$condition]])==g0];
s1 <- rownames(smpl)[as.vector(smpl[[prms$comparison$condition]])==g1];

cnt1 <- cnt0[rowSums(cnt0[, c(s0, s1), drop=FALSE])>=prms$count$total, , drop=FALSE];
cnt1 <- cnt1[rowMeans(cnt1[, c(s0, s1), drop=FALSE])>=prms$count$mean, , drop=FALSE];
cnt1 <- cnt1[rownames(cnt1) %in% rownames(anno), , drop=FALSE];
anno <- anno[rownames(cnt1), , drop=FALSE]; 

fml <- formula(prms$formula);
cnd <- unique(c(prms$comparison$condition, gsub(' ', '', strsplit(sub('~', '', prms$formula), '[+*]')[[1]])));

dds <- DESeq2::DESeqDataSetFromMatrix(countData = cnt1, colData = smpl, design = fml);

# Estimate size factor
whc <- prms$normalization$column;
if (whc>=1 & whc<=ncol(anno)) {
  gns <- which(anno[, whc]==1);
  anno <- anno[, -whc, drop=FALSE];
} else gns <- 1:nrow(anno);
dds <- DESeq2::estimateSizeFactors(dds, controlGenes=gns);
szf <- DESeq2::sizeFactors(dds);

# Run DESeq2 test
dds <- DESeq2::DESeq(dds, test='Wald', fitType='local');
res <- DESeq2::results(dds, contrast = c(cnd[1], g1, g0));

pvl <- 2*pnorm(-abs(res[, 'stat'])); 
qvl <- res[, 'padj'];
fc0 <- res[, 'log2FoldChange'];
fc1 <- DESeq2::lfcShrink(dds, contrast=c(cnd[1], g1, g0), type = 'normal')[, 2];
pvl[is.na(pvl)] <- 1;
qvl[is.na(qvl)] <- 1;
fc0[is.na(fc0)] <- 0;
fc1[is.na(fc1)] <- 0;

cnt2 <- counts(dds, normalized=TRUE);
nrm0 <- cnt2[, s0, drop=FALSE];
nrm1 <- cnt2[, s1, drop=FALSE];
mn0  <- rowMeans(nrm0);
mn1  <- rowMeans(nrm1);
stat <- cbind(mn0, mn1, fc0, fc1, pvl, qvl);
colnames(stat) <- c(paste('Mean', c(g0, g1), sep='_'), 'Log2FC', 'AdjFC', 'Pvalue', 'FDR');
saveRDS(stat, paste0(path.r, '/stat.rds'));

rlg0 <- assay(rlog(dds));
saveRDS(stat, paste0(path.r, '/rlog.rds'));

colnames(rlg0) <- paste0('rlog_', colnames(rlg0));
fll <- cbind(stat, cnt2, rlg0);

if (length(cnd) > 1) {
  adj0 <- rlg0;
  for (i in 2:length(cnd)) adj0 <- ComBat(adj0, smpl[, cnd[i]]);
  colnames(adj0) <- paste0('adj_', colnames(cnt2));
  fll <- cbind(fll, adj0);
} else adj0 <- NULL;
```

`r home.url` 

# Description
  
`r WriteDescription(yml$description)`

`r home.url` 

# Analysis and results

  - **Total number of samples: `r nrow(smpl)`**
  - **Total number of genes: `r nrow(cnt0)`**
  - **Number of genes after filtering: `r nrow(cnt1)`**
  - **Minimum number of total read: `r prms$comparison$count`**
  - **Comparison:**
    - **Condition: `r prms$comparison$condition`**
    - **Group0: `r g0`** (N0=`r length(s0)`: `r paste(s0, collapse=', ')`)
    - **Group1: `r g1`** (N1=`r length(s1)`: `r paste(s1, collapse=', ')`)

## Read count summary 

The read count matrix includes **`r ncol(cnt1)`** samples and **`r nrow(cnt1)`** genes after removing genes with total read counts few than `r prms$comparison$count`. The global average of read count per gene is **`r round(mean(cnt1), 1)`** and the overall percentage of non-zero read counts is **`r round(100*length(cnt1[cnt1>0])/length(cnt1), 2)`%**.

<div style="color:darkblue">
`r OrderTable()` Summary statistics of read counts per sample: quantiles of read count per gene, average read count per gene, and percentage of non-zero read counts.
</div>

```{r summary, include=TRUE}
smm <- round(t(apply(cnt1, 2, summary)), 2);
smm <- cbind(smm, Total=colSums(cnt1));
smm <- cbind(smm, "Positive%"=apply(cnt1, 2, function(c) round(100*length(c[c>0])/length(c), 2)))
smm <- data.frame(smpl[rownames(smm), cnd], smm, stringsAsFactors = FALSE, check.names = FALSE);

kable(smm[c(s0, s1), ]) %>% kable_styling(
    bootstrap_options = c("striped", "hover", "condensed", "responsive"), position='left', font=11, full_width=FALSE)
```

<p />

## Normalization
### Size factor

DESeq2 uses the **median ratio** to estimate a size (normalization) effect for each sample in an RNA-seq data set. Size effects are positively correlated to total read counts of samples. Therefore, a simple normalization method is to divide all read counts of each sample by its size factor. 

The size factors of all samples range between **`r round(min(szf), 3)`** and **`r round(max(szf), 3)`** (geometric mean = **`r round(exp(mean(log(szf))), 3)`**). In general, we expect a positive correlation between total read count of a sample and its size factor, and their geometric mean is close to 1.0.

```{r size_factor, include=TRUE, fig.width=12, fig.height=6, out.width='800px'}
par(mfrow=c(1, 2), mar=c(4,4,2,2));

col0 <- c('#717D7E', '#2874A6', '#CB4335');
col1 <- rep(col0[1], length(szf));
names(col1) <- names(szf);
col1[s0] <- col0[2];
col1[s1] <- col0[3];

mdn <- apply(cnt1[, names(szf)], 2, median);

plot(mdn, szf, pch='*', col=col1, cex=2, xlab='Median read count', ylab='Size factor');
legend('topleft', bty='n', pch='*', col=col0[2:3], cex=1.5, legend=c(g0, g1));
boxplot(list(szf[s0], szf[s1]), names=c(g0, g1), col=col0[-1], boxwex=0.65, ylab='Size factor');
```

`r OrderFigure()` Left: correlation between median read count per gene and size factor across all samples. Right: the distribution of size factors by groups. Average size effects of the 2 groups are **`r round(mean(szf[s0]), 2)`** vs. **`r round(mean(szf[s1]), 2)`** (p=`r round(t.test(szf[s0], szf[s1])$p.value, 4)`).


### Before vs. after normalization

After dividing the original read counts of each sample by its size factor, normalized read counts are log2-transformed (***log2(c+1)***). Data before and after normalization is compared in terms of their correlation, distribution, and variance across samples. 

```{r scatter_normalization, include=TRUE, fig.width=9.6, fig.height=4.8, out.width='960px'}
id1 <- names(sort(szf))[1];
id2 <- rev(names(sort(szf)))[1];

par(mfrow=c(1, 2), mar=c(4,4,2,2));
PlotLogScatter(cnt1[, id1], cnt1[, id2], xlab = id1, ylab = id2, main = 'Before normalization');
abline(0, 1, lty=2, col='darkblue');
PlotLogScatter(cnt2[, id1], cnt2[, id2], xlab = id1, ylab = id2, main = 'After normalization');
abline(0, 1, lty=2, col='darkblue');
```

<div style="color:darkblue">
`r OrderFigure()` Gene-level read count of two samples with the smallest (***`r id1`***) and the largest (***`r id2`***) size factors.
</div>

```{r box_normalization, include=TRUE, fig.width=9.6, fig.height=3.6, out.width='960px'}
par(mfrow=c(1, 2), mar=c(8, 4, 2, 2));
boxplot(log2(cnt1[, c(s0, s1), drop=FALSE]+1), las=3, col=col1, ylab='log2(count+1)', main='Before normalization', pch=18, boxwex=0.6);
boxplot(log2(cnt2[, c(s0, s1), drop=FALSE]+1), las=3, col=col1, ylab='log2(count+1)', main='After normalization',  pch=18, boxwex=0.6);
```
<div style="color:darkblue">
`r OrderFigure()` Distribution of read counts before and after normalization with size factors. Read counts were log2-transformed.
</div>

### Data distribution

```{r data_distribution, include=TRUE, fig.width=9.6, fig.height=6, out.width='640px'}
par(mar=c(5, 5, 2, 2));

# Distribution of average expression level
m <- rowMeans(log2(1+cnt2[, c(s0, s1), drop=FALSE]));
d <- density(m);
x <- d$x;
y <- d$y;

plot(d, type='n', yaxs='i', xaxs='i', xlim=range(x), ylim=c(0, 1.1*max(y)), main='', 
     ylab='Frequency', cex.lab=2, xaxt='n', xlab='Average normalized read count');
polygon(c(x[1], x, x[length(x)]), c(0, y, 0), border='black', col='#88888822');

x0  <- as.vector(summary(m))[c(2, 3, 5, 4)];
y0  <- sapply(x0, function(x0, x, y) y[which(abs(x-x0)==min(abs(x-x0)))], x=x, y=y);
col <- c('blue', 'red', 'orange', 'green');
segments(x0, 0, x0, y0, lty=1, col=col, lwd=3);
text(x0, c(1, 2, 3, 2)*y0/4, srt=90, labels=round(2^x0-1, 1), cex=2);
l <- c('First quantile', 'Median', 'Third quantile', 'Mean');
legend('topright', legend=l, lty=1, col=col, bty='n', lwd=2, cex=2);
axis(1, at=log2(c(0, 2^(0:20))+1), label=c(0, 2^(0:20)));
```

<div style="color:darkblue">
`r OrderFigure()` Distribution of averaged gene-level read counts after normalization by size factors. The averages often have a bi-modal (two-peak) distribution. The narrow left peak corresponds to inactive genes with lower read counts and the wider right peak corresponds to active genes expressed at different levels.
</div>


### Rlog data transformation

Regularized log (**Rlog**) transformation is another funtion implemented by the **DESeq2** package to transform the original data to reduce systemic bias between RNA-seq libraries. It does 3 things: 

  - Normalize original read counts by library size
  - Transform the read count data to log2 scale
  - Minimize difference between libraries for rows/genes with small counts (variance stablization)
  
The Rlog-transformed data has more "linear" distribution and will be used for some of the following steps, such as hierarchical clustering and PCA.

```{r rlog_dist, include=TRUE, fig.width=9.6, fig.height=3.6, out.width='960px'}
par(mfrow=c(1, 2), mar=c(8, 4, 2, 2));
d <- density(rowMeans(rlg0));
x <- d$x;
y <- d$y;
plot(d, type='l', yaxs='i', xaxs='i', xlim=range(x), ylim=c(0, 1.1*max(y)), main='After Rlog-transformation (average)', 
     ylab='Frequency', cex.lab=1, xlab='Average Log2(count)');
polygon(c(x[1], x, x[length(x)]), c(0, y, 0), border='gold', col='lightgrey');
boxplot(rlg0, las=3, col=col1, ylab='Log2(count)', main='After Rlog-transformation (sample)', pch=18, boxwex=0.6);
```

`r OrderFigure()` Data distribution after Rlog-transformation: average of all samples (left) and individual samples (right).

```{r rlog_ma, include=TRUE, fig.width=12, fig.height=4.5, out.width='800px'}
par(mai=c(0.6, 0.9, 0.4, 0.1), mfrow=c(1,2));

sd1 <- apply(rlg0, 1, sd);
vr1 <- apply(rlg0, 1, var);
ymn <- floor(log10(min(sd1[!is.na(sd1) & sd1>0])));

DESeq2::plotDispEsts(dds, ymin = 10^ymn, genecol = '#88888888', fitcol = 'orange', finalcol = NA, legend = FALSE,
                     xlab='Average Log10(count)', ylab='Variance', main='Normalized by size factor', xaxt='n', yaxt='n');
axis(1, at=10^(-10:10), label=10^(-10:10));
axis(2, at=10^(-10:10), label=10^(-10:10));

m <- 2^rowMeans(rlg0);
plot(log10(m), log10(vr1), pch=19, col='#88888888', cex=0.45, xlab='Average Log10(count)', ylab='Variance', 
     main='Normalized by Rlog', xaxt='n', yaxt='n');
axis(1, at=c(-10:10), label=10^(-10:10));
axis(2, at=c(-10:10), label=10^(-10:10));
lss <- lowess(data.frame(x=log10(m), y=log10(vr1)), f=0.1);
lines(lss, col='orange', lwd=2);
```

`r OrderFigure()` MA-plot shows the relationship between average read count and variance across samples. In the original data, genes with lower read counts have more noise and then higher variance across samples. The default DESeq2 normalization rescales the data with library size factors and the dependence remains (left). The Rlog transfromation applies a variance stablization step to penalize genes with lower read counts, so the dependence is gone (right).

`r home.url` 

## Sample analysis

Analysis of samples by comparing their global gene expression profiles, potentially to identify outlier samples and confounding variables. 

### Hierarchical clustering

```{r hier_clustering, include=TRUE, fig.width=9.6, fig.height=9.6, out.width='640px'}
corr <- cor(rlg0[gns, , drop=FALSE]);
heatmap.2(corr, key=TRUE, key.title='Correlation coefficient', keysize=1, key.xlab='', key.ylab='',
          trace='none', tracecol=NULL, margins=c(10, 10), col=rev(heat.colors(101)));

if (length(cnd) == 1) ln <- '' else {
  corr <- cor(adj0[gns, , drop=FALSE]);
  pdf(paste0(path.fig, '/heatmap_adjusted.pdf'), h=9.6, w=9.6);
  heatmap.2(corr, key=TRUE, key.title='Correlation coefficient', keysize=1, key.xlab='', key.ylab='',
          trace='none', tracecol=NULL, margins=c(10, 10), col=rev(heat.colors(101)));
  try(dev.off());
  ln <- paste0('  - [Clustering analysis](figure/heatmap_adjusted.pdf) after adjusting data for ***', 
               paste(cnd[-1], collapse=' + '), '***.')
}
```

<div style="color:darkblue">
`r OrderFigure()` Unsupervised hierarchical clustering of samples based on their pairwise correlation, using Rlog-transformed data of all genes. The lowest common node of two samples on the clustering tree indicate their similarity (lower = more similar). Colors in the heatmap correspond to correlation coefficient of a sample pair. 

`r ln`
</div>

### Principal components analysis

```{r pca, include=TRUE, fig.width=9.6, fig.height=7.2, out.width='640px'}
drawPCA <- function(d) {
  pca <- prcomp(t(d));
  
  X <- pca$x[, 1];
  Y <- pca$x[, 2];
  per <- round(summary(pca)$importance[2, 1:2]*100, 2);
  pca$importance <- summary(pca)$importance;
  
  layout(matrix(1:2, nrow=1), width=c(3,1));
  par(mai=c(1,1,.25,.25));
  
  cx <- max(0.5, min(4, 100/length(X)))
  plot(X, Y, col=col1, pch=19, cex=cx, xlim=c(min(X)*1.1, max(X)*1.1), 
       ylim=c(min(Y)*1.1, max(Y)*1.1), xlab=paste('PC1', ', ', per[1], '%', sep=''), 
       ylab=paste('PC2', ', ', per[2], '%', sep=''), cex.lab=2);
  
  text(X, Y, label=1:length(X), col='white', cex=.3*cx);
  
  par(mai=c(1, 0, 0.25, 0));
  plot(0, type='n', xlim=c(0, 100), ylim=c(1, 100), axes=FALSE, bty='n', xaxs='i', yaxs='i', xlab='', ylab='');
  
  w   <- strwidth(1:length(X), cex=1.2);
  w0  <- 1.2*80/max(w, 80);
  h0  <- 1.2*(100/length(X))/4.0;
  cex <- min(1.2, w0, h0);
  points(rep(5, length(X)), 100-(1:length(X))*4.0*cex, col=col1, pch=19, cex=2.5*cex);
  text(5+cex*5, 100-(1:length(X))*4.0*cex, labels=colnames(cnt2), adj=0, col=col1, pch=19, cex=1*cex);
  text(rep(5, length(labels)), 100-(1:length(X))*4.0*cex, labels=1:length(X), col='white', cex=0.8*cex);
  
  pca;
}

pca <- drawPCA(rlg0[gns, , drop=FALSE]);
tbl <- list(Summary=t(pca$importance), PCs=pca$x, Loading=pca$rotation);
saveRDS(tbl, paste0(path.r, '/pca.rds'));

if (length(cnd) == 1) ln <- '' else {
  pdf(paste0(path.fig, '/pca_adjusted.pdf'), w=9.6, h=7.2);
  pca2 <- drawPCA(adj0[gns, , drop=FALSE]);
  try(dev.off());
  tbl <- list(Summary=t(pca2$importance), PCs=pca2$x, Loading=pca2$rotation);
  saveRDS(tbl, paste0(path.r, '/pca_adjusted.rds'));
  ln <- paste0('  - [PC analysis](figure/pca_adjusted.pdf) after adjusting data for ***', 
               paste(cnd[-1], collapse=' + '), '***.')
}
```

<div style="color:darkblue">
`r OrderFigure()` Principal Components Analysis (PCA) is also an unsupervised analysis that converts a large number of correlated variables (genes) into a smaller set of uncorrelated variables called principal components (PCs). Each principal component accounts for certain percentage of total variance in a data set and the PCs are ordered by their percentages. This figure plots the top two PCs. Generally speaking, samples closer to each other on the 2-D space have more similar profiles of gene expression. 

`r ln`
</div>

`r home.url` 

## Differential gene expression

The analysis of differential gene expression reports a statistical table with 6 columns:

  - **Column 1/2 - Group means:** Group averages of normalized read counts (***`r g0`*** vs. ***`r g1`***).
  - **Column 3 - Log2FC:** Log2 fold change of group means (***Log2(Mean1/Mean0)***)
  - **Column 4 - AdjFC:** Log2 fold change adjusted by shrinkage esimator to penalize genes with low read counts.
  - **Column 5 - Pvalue:** Statistical significance of group difference, calculated by a negative binomial (Wald) test. 
  - **Column 6 - FDR:** Adjusted p value known as false discovery rate, calculated by the Benjamini & Hochberg method.

### DEG summary

```{r deg_plot, include=TRUE, fig.width=12, fig.height=9, out.width='800px'}
par(mai=c(0.6, 0.9, 0.4, 0.1), mfrow=c(2,2));

# M-A Plot
title <- 'A. M-A Plot';
colnames(rlg0) <- sub('rlog_', '', colnames(rlg0));
x <- rowMeans(rlg0[, s0])/2 + rowMeans(rlg0[, s1])/2; 
y <- stat[, 4];
x <- log10(2^x);
dens <- density(x);
xlim <- c(log10(1/3), dens$x[max(which(dens$y>=0.001))]);
ylim <- c(-max(y), max(y));
plot(x, y, main=title, pch=19, col='#2471A3',  cex=.25, xlab='', ylab='', cex.axis=.75, xaxt='n', xlim=xlim, ylim=ylim);
abline(h=0, lwd=1, col=1);
lines(lowess(y ~ x), lwd=2, col='#FF4444');
axis(1, at=-10:10, label=10^(-10:10));
# axis(1, at=log10(1/3), label=0);
ylab <- paste0("Log2(", prms$comparison$group1, '/', prms$comparison$group0, ')');
xlab <- "Rlog-transformed read count";
title(xlab = xlab, ylab = ylab, line = 1.6, cex.lab = 1);

# Volcano Plot
title <- 'B. Volcano Plot';
x <- stat[,'AdjFC'];
p <- stat[,'Pvalue'];
y <- -1*log10(p);
y[y==Inf] <- max(y[y<Inf]) + 1; 
z <- sqrt(abs(x*y));
cx <- z/(max(z));
xlim <- c(-max(abs(x)), max(abs(x)));
ylim <- min(10, ceiling(max(y))); 
xlab <- paste('Log2(', g1, '/', g0, ')', sep='');
plot(x, y, main=title, pch=19, col='#CB4335',  cex=0.8*cx, 
     xlab='', ylab='', cex.axis=.75, ylim=c(0, 1.1*ylim), yaxs='i', xlim=xlim, yaxt='n');
title(xlab=xlab, ylab='P value', line=1.6, cex.lab=1);
axis(2, at=0:ylim, labels=10^(-1*(0:ylim)), las=2, cex.axis=0.5);
abline(h=-1*log10(0.01), v=c(-1,1), col='#2E86C1', lty=2);
box();

# P Value Distribution
title <- 'C. P Value Distribution';
hist(p[p<1], br=seq(0, 1, 0.01), cex.axis=.75, main=title, col='#D68910', xaxs='i', yaxs='i', xlab='', ylab='');
title(xlab='P value', ylab='Count', line=1.6, cex.lab=1);
box();

# FDR
title <- 'D. False Discovery Rate';
q <- round(stat[, 'FDR'], 2);
n <- sapply(seq(min(q), 1, 0.01), function(x) length(q[q<=x]));
xlim <- 0.01*c(1, 100);
ylim <- c(1, nrow(cnt1));
plot(1, type='n', log='y', xlab='', ylab='', cex.axis=.75, xlim=xlim, ylim=ylim, main=title, xaxs='i', yaxs='i');
abline(v=seq(0, 1, .05), lty=3, col=8);
lines(seq(min(q), 1, 0.01), n, lwd=2.5, col='#7D3C98');
title(xlab='FDR cutoff', ylab='Count', line=1.6, cex.lab=1);
box();
```

<div style="color:darkblue">
`r OrderFigure()` Visualizations that summarize the differential expression of all `r nrow(cnt1)` genes.
  
  - **M-A Plot** This plot visualizes the relationship between average read counts on X-axis (**A**) and Log2 fold change on Y-axis (**M**). Each dot represents a gene. The red line is the LOWESS local smoothing fit, which indicates whether there is an overall pattern of skewed differential expression across the spectrum of gene expression levels.
  - **Volcano Plot** This plot puts together two types of differential expression statistics: **Log2 fold change** (size effect) and **P value** (statistical significance). Log2 fold change indicates magnitude of differential expression and p value indicates the consistency of change across multiple samples. Selection of differentially expressed genes usually needs to take both into account. Each dot represents a gene and its size is proportional to its distance from [0, 1]. The horizontal line corresponds to p=0.01 and the vertical lines correspond to 2.0 fold increase/decrease. 
  - **P Value Distribution** This plot shows the counts of genes whose DESeq2 p values falling into each 1% interval. The first bar on the left then indicates the number of genes with p<0.01. When the data is completely random with enough samples, the number of genes in each 1% interval will be approximately the same (uniform distribution). The genes with significant p values would be considered as false positives if this is the case. A distribution skewed to the left suggests there are indeed differentially expressed genes (true positives).
  - **False discovery rate** This plots traces the number of selected genes with each FDR (false discovery rate) cutoff. 
</div>

```{r deg_fdr, include=FALSE}
#FDR counts
c <- c(0.01, 0.02, 0.05, 0.1, 0.15, 0.2, 0.25);
n.fdr <- sapply(c, function(c) sapply(c(1, -1), function(di) 
  nrow(stat[sign(stat[, 'AdjFC'])==di & stat[, 'FDR']<=c, , drop=FALSE])));
fdr.table <- cbind(c, t(n.fdr), colSums(n.fdr)); 
deg.sub <- paste(c('Higher', 'Lower'), 'in', g1, sep='_');
rownames(fdr.table) <- NULL;
colnames(fdr.table) <- c('FDR', deg.sub, 'Total')
```

<div style="color:darkblue">
`r OrderTable()` Number of top DEGs selected via different FDR cutoffs. FDRs are calculated using the Benjamini & Hochberg method (_Controlling the false discovery rate: a practical and powerful approach to multiple testing_. Journal of the Royal Statistical Society Series B 57, 289â€“300. 1995). A FDR of 0.15 to 0.25 (15% to 25% false positives) is acceptable for most follow-up analyses, while validation of differential expression via other technologies, such as qPCR, is highly recommended. 
</div>

`r kable(fdr.table) %>% kable_styling(
    bootstrap_options = c("striped", "hover", "condensed", "responsive"), font=11, position='left', full_width=FALSE)`

`r home.url` 

### Top genes
  
```{r deg, include=FALSE}
z <- tolower(prms$top$rank[1]);
if (length(z) == 0) z <-'both'; 
if (z=='p') rnk <- -log10(stat[, 'Pvalue'])*sign(stat[,'AdjFC']) else 
  if (z=='fc') rnk <- stat[, 'AdjFC'] else 
    rnk <- sign(stat[,'AdjFC'])*sqrt(abs(log10(stat[, 'Pvalue'])*stat[, 'AdjFC'])); 
x  <- -rank(rnk); 
y  <- rank(-rnk); 
rk <- rep(NA, length(x));
rk[rnk>0] <- y[rnk>0];
rk[rnk<0] <- x[rnk<0];
names(rk) <- rownames(stat);
up <- stat[names(sort(rk[rk>0 & !is.na(rk)]))[1:max(1, prms$top$number)], , drop=FALSE];
dn <- stat[names(rev(sort(rk[rk<0 & !is.na(rk)]))[1:max(1, prms$top$number)]), , drop=FALSE];
```

```{r deg_no1, include=TRUE, fig.width=8, fig.height=3.2, out.width='800px'}
# Plot top genes
par(mfrow=c(1,2), mai=c(0.8, 0.8, 0.5, 0.2));
ind <- c(rownames(up)[1], rownames(dn)[1]);

ttl <- rownames(anno);
aid <- unlist(prms$anno);
aid <- names(aid[aid>0]);
aid <- aid[aid %in% colnames(anno)];
if (length(aid) > 0) for (i in 1:length(aid)) ttl <- paste(ttl, anno[, aid[i]], sep=' - ');
names(ttl) <- rownames(anno);

cex <- min(1, min(0.5/max(strwidth(colnames(cnt2), unit='in'))));
col <- col1[c(s0, s1)];
nch <- max(nchar(ttl[ind]));
# for (i in 1:2) {
#   barplot(cnt2[ind[i], c(s0, s1)], las=3, cex.names=cex, main=ttl[ind[i]], cex.main=25/nch, 
#           cex.axis=.75, col=col, ylab='Normalized read count');
#   abline(h=0)
# } 

for (i in 1:2) {
  if (length(cnd)==1) {
    colnames(rlg0) <- sub('^rlog_', '', colnames(rlg0));
    barplot(2^rlg0[ind[i], c(s0, s1)], las=3, cex.names=cex, main=ttl[ind[i]], cex.main=25/nch,
            cex.axis=.75, col=col, ylab='Rlog-transformed count');
    ln <- "Plotting data was normalized by Rlog.";
  } else {
    colnames(adj0) <- sub('^adj_', '', colnames(rlg0));
    barplot(2^adj0[ind[i], c(s0, s1)], las=3, cex.names=cex, main=ttl[ind[i]], cex.main=32/nch,
            cex.axis=.75, col=col, ylab='Rlog-transformed count');
    ln <- paste0("Plotting data was normalized by Rlog, and then adjusted for ***", paste(cnd[-1], collapse=' + '), '***.');
  };
  abline(h=0)
} 
```

<div style="color:darkblue">
`r OrderFigure()` The top-ranked gene with the most up- (left) and down- (right) regulated expression in `r g1`. `r ln`
</div>
  
```{r deg_heatmap, include=TRUE, fig.width=6.4, fig.height=6.4, out.width='640px'}
# Plot heatmap of top genes
par(mfrow=c(1,1));
if (length(cnd) == 1) {
  colnames(rlg0) <- sub('^rlog_', '', colnames(rlg0));
  goi <- rlg0[c(rownames(up), rownames(dn)), c(s0, s1), drop=FALSE];
  ln <- "Plotting data was normalized by Rlog.";
} else {
  colnames(adj0) <- sub('^adj_', '', colnames(rlg0));
  goi <- adj0[c(rownames(up), rownames(dn)), c(s0, s1), drop=FALSE];
  ln <- paste0("Plotting data was normalized by Rlog, and then adjusted for ***", paste(cnd[-1], collapse=' + '), '***');
}

rownames(goi) <- ttl[rownames(goi)];
DegHeatmap(goi,  col=rep(col0[-1], c(length(s0), length(s1))), plot.new=FALSE);
```

<div style="color:darkblue">
`r OrderFigure()` Heatmap of the top `r nrow(up)` and `r nrow(dn)` DEGs with the most up- (red) and down- (yellow) regulated expression in `r g1`. Each row corresponds a DEG and the colors represent its replative expression levels across samples. Samples are clustered by the genes and the columns are colored according to sample groups (blue=***`r g0`*** and red=***`r g1`***).
</div>

# Data access

```{r include=FALSE}
# DEGs
pctl <- apply(cnt2, 2, function(e) 100*rank(e)/length(e)); # percentile

path.deg1 <- paste(path.deg, deg.sub[1], sep='/');
path.deg2 <- paste(path.deg, deg.sub[2], sep='/');
path.deg1.bars <- paste(path.deg1, '/bars', sep='');
path.deg2.bars <- paste(path.deg2, '/bars', sep='');

if (!exists(path.deg1.bars)) dir.create(path.deg1.bars, showWarnings = FALSE, recursive = TRUE);
if (!exists(path.deg2.bars)) dir.create(path.deg2.bars, showWarnings = FALSE, recursive = TRUE);
ids <- c(up=rownames(up), dn=rownames(dn));
names(ids) <- paste(rep(c(path.deg1.bars, path.deg2.bars), c(nrow(up), nrow(dn))), '/', ids, '.pdf', sep='');

col <- rep(c('#16A085BB', '#E74C3CBB'), c(length(s0), length(s1)));
wid <- min(1.8, 8/max(nchar(colnames(cnt2[, c(s0, s1)]))));
if (length(cnd) == 1) {
  rlg1 <- rlg0;
  colnames(rlg1) <- sub('rlog_', '', colnames(rlg1)); 
} else {
  rlg1 <- adj0;
  colnames(rlg1) <- sub('adj_', '', colnames(rlg1)); 
}
fn.barplot <- sapply(names(ids), function(nm) {
  pdf(nm, w=8, h=6); 
  par(mai=c(1.2, 1, 0.6, 0.2));
  barplot(cnt2[ids[nm], c(s0, s1)], las=3, col=col, ylab='Normalized read count', cex.lab=2, cex.names=0.75*wid);
  title(main=ttl[ids[nm]], cex.main=1);
  par(mai=c(1.2, 1, 0.6, 0.2));
  barplot(2^rlg1[ids[nm], c(s0, s1)], las=3, col=col, ylab='Rlog-transformed read count', cex.lab=2, cex.names=0.75*wid);
  title(main=ttl[ids[nm]], cex.main=1);
  par(mai=c(1.2, 1.2, 0.6, 0.2));
  barplot(pctl[ids[nm], c(s0, s1)], las=3, col=col, ylab='Percentile (%)', ylim=c(0, 100), cex.lab=2, cex.names=0.75*wid);
  title(main=ttl[ids[nm]], cex.main=1);
  
  dev.off();
  nm;
});

up.tbl <- data.frame(anno[rownames(up), , drop=FALSE], up, stringsAsFactors=FALSE, check.names=FALSE);
up.url <- AddHref(rownames(up.tbl), paste0('https://www.ncbi.nlm.nih.gov/gene/?term=', rownames(up.tbl)));
up.fig <- AddHref('Figure', paste('bars/', rownames(up), '.pdf', sep=''));
up.tbl <- cbind(ID=up.url, up.tbl, Barplot=up.fig);
CreateDatatable(up.tbl, paste0(path.deg1, '/index.html'), rownames = FALSE)->x;

dn.tbl <- data.frame(anno[rownames(dn), , drop=FALSE], dn, stringsAsFactors=FALSE, check.names=FALSE);
dn.url <- AddHref(rownames(dn.tbl), paste0('https://www.ncbi.nlm.nih.gov/gene/?term=', rownames(dn.tbl)));
dn.fig <- AddHref('Figure', paste('bars/', rownames(dn), '.pdf', sep=''));
dn.tbl <- cbind(ID=dn.url, dn.tbl, Barplot=dn.fig);
CreateDatatable(dn.tbl, paste0(path.deg2, '/index.html'), rownames = FALSE)->x;

# All genes
stat.table <- data.frame(anno[rownames(stat), , drop=FALSE], stat, round(cnt2[, c(s0, s1), drop=FALSE], 2), 
                         stringsAsFactors=FALSE, check.names=FALSE);
stat.formatted <- FormatNumeric(cbind(ID=rownames(stat.table), stat.table));
ind <- prms$anno$entrez;
if (ind >= 0) stat.formatted[, ind+1] <- AddHref(stat.formatted[, ind+1], UrlEntrezGene(stat.formatted[, ind+1]));
CreateDatatable(stat.formatted, fn = paste(path.deg, 'all_genes.html', sep='/'), rownames = FALSE);

deg <- list(sample=smpl, anno=anno, parameter=prms, count=list(original=cnt1, normalized=cnt2, rlog=rlg0, adjusted=adj0), pca=pca);
deg$stat <- stat;
deg$deg  <- list(up=up, down=dn);
saveRDS(deg, file=paste0(path.r, '/deg.rds'));

xls <- list(stat, up, dn);
xls <- lapply(xls, function(x) 
  data.frame(anno[rownames(x), ], x, cnt2[rownames(x), c(s0, s1)], stringsAsFactors=FALSE, check.names=FALSE));
xls <- lapply(xls, FormatNumeric);
names(xls) <- c('All genes', paste('Higher in', g1), paste('Lower in', g1));
WriteExcel(xls, fileName = paste0(path.deg, '/deg'));

### PCA
pca.table <- data.frame(t(pca$importance), pca$x, stringsAsFactors = FALSE, check.names = FALSE);
CreateDatatable(FormatNumeric(pca.table, 3), paste0(path.tbl, '/pca.html'));
CreateDatatable(FormatNumeric(pca$rotation, 6), paste0(path.tbl, '/pca_loading.html'));

xls <- list(PCs=pca.table, Loading=pca$rotation);
WriteExcel(xls, fileName = paste0(path.tbl, '/pca'));

### Zip 
fz1 <- paste0(path.deg, '/deg.zip');
fz2 <- paste0(path.r, '/R.zip');
fz3 <- paste0(path, '/result.zip');
if (file.exists(fz1)) file.remove(fz1);
if (file.exists(fz2)) file.remove(fz2);
if (file.exists(fz3)) file.remove(fz3);
zip(fz1, path.deg, zip = 'zip');
zip(fz2, path.r, zip = 'zip');
zip(fz3, path, zip = 'zip');
```

<p />

## Browse online

**Differential gene expression:**

  - [All genes](deg/all_genes.html)
    - [`r nrow(up)` DEGs with higher expression in `r g1`](`r paste('deg', deg.sub[1], 'index.html', sep='/')`)
    - [`r nrow(dn)` DEGs with lower expression in `r g1`](`r paste('deg', deg.sub[2], 'index.html', sep='/')`)

**Principal components analysis**

  - [Principal components](table/pca.html)
  - [Gene loading](table/pca_loading.html)

## Download 

  - [DEG (Excel)](deg/deg.xlsx)
  - [DEG (All files)](deg/deg.zip)
  - [PCA (Excel)](table/pca.xlsx)
  - [R objects](R/R.zip)
  - [All files](result.zip)

`r home.url` 

***

# Appendix 

Check out the **[RoCA home page](http://zhezhangsh.github.io/RoCA)** for more information.  

## Fold change vs. log2(fold change)

The terms to represent differential expression can be used quite confusingly. In this report, **fold change** refers the ratio of two group means in their unlogged form. So a fold change of 2.0 means the average of the second group is increased to twice of the average of the first group; similarly, a fold change of 0.5 means the average is reduced to half. **Log2(fold change)** equals to the log2-transformation of the fold change. The table below gives a few examples of the conversion of these 2 variables. **Log2(fold change)** is more suitable for statistical analysis since it is symmetric around 0. 

<div style="color:darkblue">
**Supplemental Table 1.** Fold Change vs. Log(Fold Change) vs. Percentage Change
</div>
  
```{r fold_change, eval=TRUE, include=TRUE}
c<-c(1.25, 1.5, 2, 4, 8);
fc<-c(1/rev(c), 1, c);
lg<-log2(fc);
pct<-100*(fc-1);
t<-round(cbind(fc, lg, pct), 3);
colnames(t)<-c('Fold change', 'Log2(fold change)', 'Percentage change (%)');

kable(t) %>% kable_styling(
    bootstrap_options = c("striped", "hover", "condensed", "responsive"), full_width=FALSE); 
```

<p />

## References

  - **R:** R Development Core Team, 2011. _R: A Language and Environment for Statistical Computing._ ISBN 3-900051-07-0. [Home page](http://www.R-project.org).
  - **Bioconductor:** Gentleman RC et al., 2004. _Bioconductor: open software development for computational biology and bioinformatics._ Genome Biology. [Home page](http://www.bioconductor.org).
  - **DESeq2:** Love MI, Huber W, Anders S (2014). _Moderated estimation of fold change and dispersion for RNA-seq data with DESeq2._ [Genome Biology, 15, 550](https://genomebiology.biomedcentral.com/articles/10.1186/s13059-014-0550-8).
  - **[RoCA](http://zhezhangsh.github.io/RoCA)** 
  - **[Awsomics](awsomics.org)**

## Reproduce this report

To reproduce this report: 

  1. Find the data analysis template you want to use and an example of its pairing YAML file  [here](https://github.com/zhezhangsh/RoCA/wiki/Templates-and-examples) and download the YAML example to your working directory

  2. To generate a new report using your own input data and parameter, edit the following items in the YAML file:

    - **output**        : where you want to put the output files
    - **home**          : the URL if you have a home page for your project
    - **analyst**       : your name
    - **description**   : background information about your project, analysis, etc.
    - **input**         : where are your input data, read instruction for preparing them
    - **parameter**     : parameters for this analysis; read instruction about how to prepare input data

  3. Run the code below within ***R Console*** or ***RStudio***, preferablly with a new R session:

```{r reproduce_report, eval=FALSE, echo=TRUE}
if (!require(devtools)) { install.packages('devtools'); require(devtools); }
if (!require(RCurl)) { install.packages('RCurl'); require(RCurl); }
if (!require(RoCA)) { install_github('zhezhangsh/RoCAR'); require(RoCA); }

CreateReport(filename.yaml);  # filename.yaml is the YAML file you just downloaded and edited for your analysis
```

If there is no complaint, go to the _output_ folder and open the ***index.html*** file to view report. 

## Session information

```{r session_info, echo=FALSE}
sessionInfo(); 
```

`r home.url`

***
_END OF DOCUMENT_


